{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJBs_flRovLc"
      },
      "source": [
        "## Using spaCy for NLP Tasks\n",
        "\n",
        "This notebook demonstrates how to install and use spaCy to perform various Natural Language Processing (NLP) tasks.\n",
        "\n",
        "In today’s lesson we will:\n",
        "\n",
        "- Install spaCy and download its statistical models.\n",
        "- Read and process a text file.\n",
        "- Perform Named Entity Recognition (NER) to extract entities from text.\n",
        "- Visualize entity counts.\n",
        "- Explore and customize the spaCy pipeline (including using the EntityRuler)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Installation\n",
        "To get started, you must install spaCy and the English language model.\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "1. Use `pip install spacy` to install the core library.\n",
        "2. Download the English model (`en_core_web_sm`) which includes the statistical model for English.\n"
      ],
      "metadata": {
        "id": "Ans8WJUUj8qI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "s8aj7OGAkCcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Loading the spaCy Model\n",
        "\n",
        "Once downloaded, those models can be opened via **spacy.load('model_name')** in python. Therefore, you can verify if the models were downloaded successfully by running the following code:"
      ],
      "metadata": {
        "id": "QCjfqkKMkrY-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJr_9dXGpJ05"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Reading a Text File\n",
        "Here, we read in a text file that contains a chapter from *The Fellowship Of The Ring*. Make sure the file is in your working directory (or provide the full path).\n",
        "\n",
        "**Key Steps:**\n",
        "- Open the file using Python’s built-in `open()` function.\n",
        "- Read the content into a variable.\n",
        "- Adjust `nlp.max_length` to avoid errors when processing long texts.\n"
      ],
      "metadata": {
        "id": "iFPkM3QLc9qf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the file path (adjust this path if your file is stored elsewhere)\n",
        "lotr_script = '/content/The Fellowship Of The Ring_Ch1 (1).txt'\n",
        "\n",
        "# Read the file content\n",
        "with open(lotr_script, 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# Adjust the maximum allowed length for the NLP model to process the full text\n",
        "nlp.max_length = len(text)\n",
        "\n",
        "# Process the text with the spaCy model\n",
        "doc = nlp(text)"
      ],
      "metadata": {
        "id": "f9MWj4EuNvNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gE-Ez1qtyIA"
      },
      "outputs": [],
      "source": [
        "# Increase the max_length to handle the large text, avoids an error\n",
        "nlp.max_length = len(text) # Sets the maximum length to the length of the text\n",
        "\n",
        "doc = nlp(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Named Entity Recognition (NER)\n",
        "\n",
        "Named Entity Recognition identifies and classifies entities (like names of people, places, or organizations) in text.\n",
        "**What we'll do:**\n",
        "- Extract entities from the processed document.\n",
        "- Create a Pandas DataFrame that shows the entity text and its corresponding label."
      ],
      "metadata": {
        "id": "exe29dKGjGir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a list to collect entity data\n",
        "entities_data = []\n",
        "\n",
        "# Extract each entity and its label from the document\n",
        "\n",
        "\n",
        "# Convert the list into a DataFrame for easier viewing\n",
        "\n",
        "# Display the entities"
      ],
      "metadata": {
        "id": "_5etHS43jL0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Analyzing Entity Data\n",
        "Let's examine:\n",
        "- **Text and Label Frequency:**  \n",
        "Display the most common entity texts and their labels.\n",
        "- **Entity Details:**  \n",
        "Use spaCy's built-in explanation function to understand what a specific label (e.g., \"FAC\") means."
      ],
      "metadata": {
        "id": "oH8kcexJU5g8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the top 15 most common texts and labels\n",
        "\n",
        "# Explain a specific entity label\n"
      ],
      "metadata": {
        "id": "K0R0AmwYV_qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display combinations of text and label counts\n"
      ],
      "metadata": {
        "id": "drU2gC30_g8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List unique labels in the dataset\n"
      ],
      "metadata": {
        "id": "ws6P7bHT_i0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  6. Exploring the NLP Pipeline\n",
        "[NLP Pipeline Documentation](https://spacy.io/usage/processing-pipelines#processing)\n",
        "\n",
        "You can inspect the components of the NLP pipeline `nlp.pipeline`."
      ],
      "metadata": {
        "id": "xHksIATSjXEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Spacy's language model pipeline\n"
      ],
      "metadata": {
        "id": "q9iiD5GBdTNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Visualizing Entities with DisplaCy\n",
        "DisplaCy is spaCy’s visualization tool for rendering entities and dependencies in Jupyter notebooks.\n"
      ],
      "metadata": {
        "id": "Gw9yYQJlWbpu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "\n",
        "# Render entities in the processed document using DisplaCy\n",
        "displacy.render(doc, style = \"ent\", jupyter = True)"
      ],
      "metadata": {
        "id": "DafBeVakWgQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Identifying Issues in the Named Entity Recognizer\n",
        "\n",
        "Use the [Lord of the Rings Wiki](https://lotr.fandom.com/wiki/Main_Page) if you need help\n",
        "\n",
        "Example Issues: ?"
      ],
      "metadata": {
        "id": "yiKdRq51h6BD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Creating Custom Entity Recognizers with the EntityRuler\n",
        "\n",
        "Custom patterns can be added to the pipeline using spaCy's `EntityRuler`. This allows us to capture entities that might be missed by the statistical model.\n",
        "\n",
        "**Steps:**\n",
        "- Define custom entity patterns (as a list of dictionaries).\n",
        "- Check if the \"ner\" component exists and add the EntityRuler accordingly."
      ],
      "metadata": {
        "id": "OEXt_fWGgvw-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[EntityRuler Documentation](https://spacy.io/api/entityruler#add_patterns)"
      ],
      "metadata": {
        "id": "cLIskVAMQ29B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define custom entity patterns for names, locations, and other entities\n",
        "entity_patterns = [\n",
        "\n",
        "\n",
        " ]\n",
        "\n",
        "#Add EntityRuler to the pipeline\n",
        "#ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
        "#ruler.add_patterns(entity_patterns)\n",
        "\n",
        "#Access the existing entity_ruler\n",
        "#ruler = nlp.get_pipe(\"entity_ruler\")\n",
        "\n",
        "#Add your custom patterns\n",
        "#ruler.add_patterns(entity_patterns)"
      ],
      "metadata": {
        "id": "giLScuq6KIel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the \"ner\" pipe exists. If it does, add the EntityRuler before it.\n",
        "\n",
        "    # If entity_ruler already exists, simply add patterns to it.\n",
        "\n",
        "    # If the NER component does not exist, add both the EntityRuler and the NER component.\n",
        "\n",
        "# Check updated pipeline labels\n"
      ],
      "metadata": {
        "id": "xZMQGkZXFv2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10. Testing the Custom Entity Ruler\n",
        "Run a sample sentence through the updated pipeline to check if your custom patterns are recognized.\n"
      ],
      "metadata": {
        "id": "3Opw-lzPZWsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "\n",
        "doc_2 = nlp(\"Gandalf went to Bilbo's house for his birthday because he was my precious which is the Ring.\")\n",
        "displacy.render(doc_2, style=\"ent\", jupyter=True)"
      ],
      "metadata": {
        "id": "2O5Ge2r3LP9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11. Re-Processing the Full Text\n",
        "Now that we have updated the pipeline with our custom patterns, re-run the full text to see how the recognizer performs.\n"
      ],
      "metadata": {
        "id": "GPOU5FyuQ-Md"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-process the text with the updated pipeline\n",
        "nlp.max_length = len(text)\n",
        "doc = nlp(text)\n",
        "\n",
        "displacy.render(doc, style=\"ent\", jupyter=True)"
      ],
      "metadata": {
        "id": "62RVMVg6M3DW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 12. Re-Analyzing Entity Data\n",
        "Let's again create a DataFrame from the updated document to see if our custom recognitions improved entity extraction."
      ],
      "metadata": {
        "id": "qeVGXJYmYySk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect entities from the updated document\n",
        "entities_data = []\n",
        "for ent in doc.ents:\n",
        "    entities_data.append({\n",
        "        'text': ent.text,\n",
        "        'label': ent.label_\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame and display\n",
        "ent_df = pd.DataFrame(entities_data)\n",
        "ent_df\n",
        "\n",
        "# %%\n",
        "# Show value counts for text and label combinations after the update\n",
        "print(\"Updated Text and Label Combinations (Top 20):\")\n",
        "print(ent_df[['text', 'label']].value_counts()[:20])"
      ],
      "metadata": {
        "id": "Jh-a6rd-mDpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 13. Visualizing Entity Data\n",
        "Finally, we create a bar plot to visualize the top 10 most common text and label combinations.\n",
        "**Steps:**\n",
        "- Use Pandas to compute counts.\n",
        "- Plot the counts using Seaborn and Matplotlib.\n",
        "\n",
        "**Tree Map**\n",
        "- The `color` parameter is set to `label` so that each entity label gets a distinct color.\n",
        "\n",
        "- The `path` parameter defines a hierarchy where entities are grouped by their `label` first, then by `text`.\n",
        "\n",
        "- This interactive treemap allows students to easily see how different entity labels contribute to the overall counts."
      ],
      "metadata": {
        "id": "uVbasK5wXAX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# Prepare the data for visualization: top 10 entity combinations\n",
        "top_10_ents = ent_df[['text', 'label']].value_counts().head(10).reset_index(name='counts')\n",
        "\n",
        "# Create a treemap using a hierarchical structure (first by label, then by text)\n",
        "fig = px.treemap(top_10_ents,\n",
        "                path=['label', 'text'],\n",
        "                values='counts',\n",
        "                title='Top 10 Text and Label Combinations (Treemap)',\n",
        "                color='label')\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "8IZa1cJHlamc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}